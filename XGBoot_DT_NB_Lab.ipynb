{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "087d86f2-bf4f-4179-8f76-1cfea4261b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# pip install xgboost pandas scikit-learn matplotlib\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f1e4711-be8f-441a-997a-387f9ef487ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- XGBoost Evaluation ---\n",
      "Accuracy: 0.94\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class_0       1.00      0.93      0.96        14\n",
      "     class_1       0.88      1.00      0.93        14\n",
      "     class_2       1.00      0.88      0.93         8\n",
      "\n",
      "    accuracy                           0.94        36\n",
      "   macro avg       0.96      0.93      0.94        36\n",
      "weighted avg       0.95      0.94      0.94        36\n",
      "\n",
      "\n",
      "--- Decision Tree Evaluation ---\n",
      "Accuracy: 0.94\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class_0       0.93      0.93      0.93        14\n",
      "     class_1       0.93      1.00      0.97        14\n",
      "     class_2       1.00      0.88      0.93         8\n",
      "\n",
      "    accuracy                           0.94        36\n",
      "   macro avg       0.95      0.93      0.94        36\n",
      "weighted avg       0.95      0.94      0.94        36\n",
      "\n",
      "\n",
      "--- Naive Bayes Evaluation ---\n",
      "Accuracy: 1.00\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class_0       1.00      1.00      1.00        14\n",
      "     class_1       1.00      1.00      1.00        14\n",
      "     class_2       1.00      1.00      1.00         8\n",
      "\n",
      "    accuracy                           1.00        36\n",
      "   macro avg       1.00      1.00      1.00        36\n",
      "weighted avg       1.00      1.00      1.00        36\n",
      "\n",
      "\n",
      "Decision Tree Feature Importances:\n",
      "alcohol: 0.0190\n",
      "malic_acid: 0.0000\n",
      "ash: 0.0209\n",
      "alcalinity_of_ash: 0.0000\n",
      "magnesium: 0.0000\n",
      "total_phenols: 0.0000\n",
      "flavanoids: 0.4111\n",
      "nonflavanoid_phenols: 0.0000\n",
      "proanthocyanins: 0.0000\n",
      "color_intensity: 0.3849\n",
      "hue: 0.0000\n",
      "od280/od315_of_diluted_wines: 0.0000\n",
      "proline: 0.1641\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import xgboost as xgb  # For the XGBoost model\n",
    "from sklearn.datasets import load_wine  # For loading the Wine dataset\n",
    "from sklearn.model_selection import train_test_split  # For splitting data\n",
    "from sklearn.metrics import accuracy_score, classification_report  # For evaluation metrics\n",
    "from sklearn.tree import DecisionTreeClassifier  # For Decision Tree\n",
    "from sklearn.naive_bayes import GaussianNB  # For Naive Bayes\n",
    "\n",
    "# Step 1: Load the Wine dataset\n",
    "wine = load_wine()\n",
    "X = wine.data  # Features (13 columns)\n",
    "y = wine.target  # Target (3 classes: 0, 1, 2)\n",
    "\n",
    "# Step 2: Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 3: Function to evaluate a model (for reusability)\n",
    "def evaluate_model(model, model_name):\n",
    "    model.fit(X_train, y_train)  # Train the model\n",
    "    y_pred = model.predict(X_test)  # Make predictions\n",
    "    accuracy = accuracy_score(y_test, y_pred)  # Calculate accuracy\n",
    "    print(f\"\\n--- {model_name} Evaluation ---\")\n",
    "    print(f\"Accuracy: {accuracy:.2f}\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred, target_names=wine.target_names))\n",
    "\n",
    "# Step 4: Train and evaluate XGBoost model\n",
    "xgb_model = xgb.XGBClassifier(\n",
    "    # use_label_encoder=False,  # Avoids warnings in newer versions\n",
    "    eval_metric='mlogloss'  # Multiclass log loss for evaluation\n",
    ")\n",
    "evaluate_model(xgb_model, \"XGBoost\")\n",
    "\n",
    "# Step 5: Train and evaluate Decision Tree model\n",
    "dt_model = DecisionTreeClassifier(max_depth=5, random_state=42)  # Using default parameters\n",
    "evaluate_model(dt_model, \"Decision Tree\")\n",
    "\n",
    "# Step 6: Train and evaluate Naive Bayes model\n",
    "nb_model = GaussianNB()  # Gaussian Naive Bayes for continuous features\n",
    "evaluate_model(nb_model, \"Naive Bayes\")\n",
    "\n",
    "# Optional: Feature importance for Decision Tree (XGBoost already has it in the original code)\n",
    "if hasattr(dt_model, 'feature_importances_'):\n",
    "    importances = dt_model.feature_importances_\n",
    "    feature_names = wine.feature_names\n",
    "    print(\"\\nDecision Tree Feature Importances:\")\n",
    "    for name, importance in zip(feature_names, importances):\n",
    "        print(f\"{name}: {importance:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0bb64088-a20e-4820-9570-d8e1fdb3ab98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1.040e+00, 3.920e+00,\n",
       "        1.065e+03],\n",
       "       [1.320e+01, 1.780e+00, 2.140e+00, ..., 1.050e+00, 3.400e+00,\n",
       "        1.050e+03],\n",
       "       [1.316e+01, 2.360e+00, 2.670e+00, ..., 1.030e+00, 3.170e+00,\n",
       "        1.185e+03],\n",
       "       ...,\n",
       "       [1.327e+01, 4.280e+00, 2.260e+00, ..., 5.900e-01, 1.560e+00,\n",
       "        8.350e+02],\n",
       "       [1.317e+01, 2.590e+00, 2.370e+00, ..., 6.000e-01, 1.620e+00,\n",
       "        8.400e+02],\n",
       "       [1.413e+01, 4.100e+00, 2.740e+00, ..., 6.100e-01, 1.600e+00,\n",
       "        5.600e+02]], shape=(178, 13))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Sklearn-Env",
   "language": "python",
   "name": "sklearn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
