{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08b366bc-138f-4790-86fc-397e6c0b69af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb  # For the XGBoost model\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import random\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score,\n",
    "                             roc_auc_score, confusion_matrix, classification_report)\n",
    "from sklearn.preprocessing import LabelEncoder, OrdinalEncoder\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab0368e-0bcf-47ff-8c4f-75590429e75c",
   "metadata": {},
   "source": [
    "### 1. Data Preparation\n",
    "\n",
    "Convert categorial and non-number data to numerical data.\n",
    "Sine most ML algorithm do only accept numerical data !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32c1055c-eca4-4f77-914a-194ddcc4f407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class of y : ['<=50K' '>50K']\n",
      "Number for <=50K : [0]\n",
      "'Number for >50K : [1]\n"
     ]
    }
   ],
   "source": [
    "# import dataset and do data preparation \n",
    "adult_tmp = pd.read_csv(\"C:\\\\Users\\\\pixal\\\\Desktop\\\\WPy64-312101\\\\notebooks\\\\adult\\\\adult_with_heading.csv\")\n",
    "adult_tmp['cap-gain-loss'] = adult_tmp['capital-gain'] + adult_tmp ['capital-loss']\n",
    "\n",
    "# column has prefix space. Finally space removed by hand as programming is troublesome!\n",
    "# adult_tmp.loc[:,'marital-status'] = adult_tmp['marital-status'].str.lstrip()  \n",
    "\n",
    "# convert dataset for X (predicators)\n",
    "mar_cat = adult_tmp[['marital-status']]\n",
    "mar_cat = mar_cat.replace({'Married-AF-spouse':'Married', 'Married-civ-spouse':'Married', 'Married-spouse-absent':'Married'})\n",
    "dummies = pd.get_dummies(mar_cat['marital-status'], dtype='uint8')\n",
    "X = pd.concat((adult_tmp['cap-gain-loss'], dummies), axis=1)\n",
    "\n",
    "# convert dataset for targets\n",
    "le_class = LabelEncoder() # convert target, one dimension only !!\n",
    "y = le_class.fit_transform(adult_tmp['class'])\n",
    "\n",
    "print(\"Class of y :\", le_class.classes_)            # show numbers assignment\n",
    "print(f\"Number for <=50K : {le_class.transform(['<=50K'])}\") \n",
    "print(f\"'Number for >50K : {le_class.transform(['>50K'])}\") \n",
    "\n",
    "\n",
    "# y = adult_train[['class']]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0071c7f6-72af-4653-b5f4-1531997ec141",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Decision Tree - gini Evaluation ---\n",
      "Accuracy: 0.81\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.98      0.89      4942\n",
      "           1       0.80      0.30      0.44      1571\n",
      "\n",
      "    accuracy                           0.81      6513\n",
      "   macro avg       0.81      0.64      0.66      6513\n",
      "weighted avg       0.81      0.81      0.78      6513\n",
      "\n",
      "\n",
      "--- Decision Tree - entropy Evaluation ---\n",
      "Accuracy: 0.81\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.98      0.89      4942\n",
      "           1       0.80      0.30      0.44      1571\n",
      "\n",
      "    accuracy                           0.81      6513\n",
      "   macro avg       0.81      0.64      0.66      6513\n",
      "weighted avg       0.81      0.81      0.78      6513\n",
      "\n",
      "\n",
      "--- Naive Bayes Evaluation ---\n",
      "Accuracy: 0.80\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.97      0.88      4942\n",
      "           1       0.74      0.28      0.40      1571\n",
      "\n",
      "    accuracy                           0.80      6513\n",
      "   macro avg       0.77      0.62      0.64      6513\n",
      "weighted avg       0.79      0.80      0.77      6513\n",
      "\n",
      "\n",
      "--- XGBoost Evaluation ---\n",
      "Accuracy: 0.83\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      1.00      0.90      4942\n",
      "           1       0.98      0.32      0.48      1571\n",
      "\n",
      "    accuracy                           0.83      6513\n",
      "   macro avg       0.90      0.66      0.69      6513\n",
      "weighted avg       0.86      0.83      0.80      6513\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# evaluate model\n",
    "def evaluate_model(model, model_name):\n",
    "    model.fit(X_train, y_train)  # Train the model\n",
    "    y_pred = model.predict(X_test)  # Make predictions\n",
    "    accuracy = accuracy_score(y_test, y_pred)  # Calculate accuracy\n",
    "    print(f\"\\n--- {model_name} Evaluation ---\")\n",
    "    print(f\"Accuracy: {accuracy:.2f}\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "# build Decision Tree\n",
    "\n",
    "dtc5_model = DecisionTreeClassifier(criterion = \"gini\", max_leaf_nodes=5)\n",
    "evaluate_model(dtc5_model, \"Decision Tree - gini\")\n",
    "\n",
    "# build Decision Tree with entropy\n",
    "dt_model = DecisionTreeClassifier(criterion = \"entropy\", max_leaf_nodes=5)\n",
    "evaluate_model(dt_model, \"Decision Tree - entropy\")\n",
    "\n",
    "# use Navie Bayes classification\n",
    "nb_model = GaussianNB()\n",
    "evaluate_model(nb_model, \"Naive Bayes\")\n",
    "\n",
    "\n",
    "# XGBoot\n",
    "xgb_model = xgb.XGBClassifier(\n",
    "    # use_label_encoder=False,  # Avoids warnings in newer versions\n",
    "    eval_metric='mlogloss'  # Multiclass log loss for evaluation\n",
    ")\n",
    "evaluate_model(xgb_model, \"XGBoost\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08948b67-4bf5-4ac4-803b-b070c5e7b9dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Sklearn-Env",
   "language": "python",
   "name": "sklearn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
